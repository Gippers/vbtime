{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Game Data\n",
    "\n",
    "> Scrapes VACT Game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scrape_game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "#import gluonts\n",
    "from nbdev import *\n",
    "#import urllib.request\n",
    "#from bs4 import BeautifulSoup\n",
    "from fastcore.test import *\n",
    "#import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO \n",
    "- check the connection works\n",
    "- Scrape the web page\n",
    "- format correctly the\n",
    "- place into dataframes\n",
    "- if small, save locally\n",
    "\n",
    "See ivi for ideas on how to do.\n",
    "\n",
    "# How to scrape website with bs4\n",
    "#https://www.geeksforgeeks.org/how-to-scrape-data-from-local-html-files-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vact_url = \"https://scheduler.leaguelobster.com/1108252/capital-volleyball-league/2022-cvl-season/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object page\n",
    "#page = requests.get(vact_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that website is accessible, should return code 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_eq(urllib.request.urlopen(vact_url).getcode(), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser-lxml = Change html to Python friendly format\n",
    "# Obtain page's information\n",
    "#soup = BeautifulSoup(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain information from tag <table>\n",
    "#table1 = soup.find('div', 'class'='schedule-date-container col-xs-12')\n",
    "#table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
